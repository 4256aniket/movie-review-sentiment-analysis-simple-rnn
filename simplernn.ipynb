{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000 #vocabulary size\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple rnn\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128,input_length=max_len))\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1313025 (5.01 MB)\n",
      "Trainable params: 1313025 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of EarlyStopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 62s 98ms/step - loss: 203498.5938 - accuracy: 0.7539 - val_loss: 0.4543 - val_accuracy: 0.7902\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 61s 98ms/step - loss: 0.3733 - accuracy: 0.8503 - val_loss: 0.4483 - val_accuracy: 0.8024\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.2872 - accuracy: 0.8860 - val_loss: 0.4763 - val_accuracy: 0.8054\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.2734 - accuracy: 0.9042 - val_loss: 0.4675 - val_accuracy: 0.7890\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.2299 - accuracy: 0.9153 - val_loss: 0.4639 - val_accuracy: 0.8092\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 65s 103ms/step - loss: 0.1785 - accuracy: 0.9365 - val_loss: 0.5055 - val_accuracy: 0.8170\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.1529 - accuracy: 0.9470 - val_loss: 0.5345 - val_accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "# train the model with earlystopping\n",
    "history = model.fit(\n",
    "    X_train,y_train,epochs=10,batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aniketkumar/Developer/projects/text-classification-rnn/venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# save the model file\n",
    "model.save('simple_rnn_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
